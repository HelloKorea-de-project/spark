## 목적 ##
- 실제 회사에서 데일리 배치로 다룰만한 크기의 대량의 데이터를 생산해 redshift 테이블에 적재한 뒤, spark SQL을 통해 쿼리를 실행해보았다


## 실험 환경 ##
- AWS Glue pyspark 이용, G.1X worker, 10 DPUs


## 실험 내용 ##
### 1. 더미데이터 생성 ###
로컬에서 더미데이터 생성시, 1000만 레코드의 데이터를 생성하는데 1시간 15분 정도가 소요되어 억 단위의 레코드를 생성하려면 훨씬 많은 시간이 소요될 것으로 예상했다.
따라서 현 상황에서 이용할 수 있는 glue의 serverless spark로 더미데이터를 생성했다

1000만 레코드 기준 파티션을 7개로 나눠 실행한 결과 11분 정도 소요된 것을 확인했다
- 항공권 검색 로그 : 1억 3천만건
- 항공권 클릭 로그 : 4억건
- 항공권 구매 로그 : 2천만건
- 세션 채널 타임스탬프 : 4백만건
- 사용자 정보 : 4백만건

### 2. spark SQL을 이용한 쿼리 실행 ###
#### 1) 균등/불균등 분포인 컬럼 기준으로 파티셔닝 ####
4억건의 레코드가 있는 항공권 클릭 로그 테이블을 2가지 기준으로 파티셔닝해 S3에 저장했다.
하나는 불균등한 분포를 가지는 출발 공항을 기준으로 파티셔닝했고, 다른 하나는 균등한 분포를 가지는 사용자 아이디를 기준으로 파티셔닝했다.

쿼리 성능 비교를 위해 채널별 구매수를 연산하는 쿼리(세션 채널 타임스탬프 & 항공권 클릭 로그 & 항공권 구매 로그)를 시행했는데,
균등한 분포를 가진 파티셔닝을 불러와 처리했을때 1분 33초, 불균등한 분포를 가진 파티셔닝을 불러와 처리했을 때 1분 51초가 소요됐다.

셔플이 발생한 정도를 살펴보면, 불균등한 분포보다 균등한 분포로 파티셔닝했을때 셔플된 레코드 수가 1/5로 현저히 적은 것을 확인할 수 있었다

#### 2) 쿼리 최적화 ####
쿼리 자체에 대한 최적화를 실험하기 위해 하나는 조인 후 집계하는 쿼리를, 다른 하나는 집계 후 조인하는 쿼리를 실행해봤다.
실험한 테이블은 사용자 정보 테이블과 항공권 클릭 로그 테이블로 조인 후 집계하는 쿼리는 2분 8초가 소요됐고, 집계 후 조인을 수행하는 쿼리는 40초가 더 빠른 1분 28초가 소요됐다.

조인에 해당하는 스테이지만 확인했을 때, 집계하지 않고 조인 수행시 2억 8천만행의 셔플이 발생햇고, 집계 후 조인시 450만행의 셔플이 발생했다

#### 3) 셔플 파티션 최적화 ####
glue serverless spark를 사용하면서, 자동으로 셔플 파티션이 최적화되어 36개 정도가 사용되는 것을 확인했다. 실험을 통해 셔플 파티션을 줄였을 때와 늘렸을때 차이를 확인하고 싶었다

셔플 파티션을 5개로 설정했을때, 각 태스크마다 3.3GB의 메모리 스필(셔플시 메모리가 충분하지 못할때 발생하는데, 메모리 내에서 처리하기 힘든 데이터를 임시로 디스크나 기타 스토리지에 저장 후 다시 불러와야해
이 과정에서 직렬화/역직렬화 과정으로 시간 소요가 길어진다)이 발생했으며 시간은 4분 33초가 소요됐다. 반면 셔플 파티션을 100개로 설정했을때, 메모리 스필이 발생하지 않았으며 2분 4초가 소요된 것을 확인했다

셔플 파티션을 5개로 극단적으로 줄여 실험해봤지만, 실무에서 적절한 셔플 파티션을 사용하는 것은 메모리 스필의 위험성을 줄이고 최적의 시간 성능을 낼 것으로 예상된다


## 결론 ##
spark를 사용할땐 병렬 처리의 효율성을 높이기 위한 여러 방법이 있다.
이 실험에서 사용한 방법들은 쿼리 최적화, 파티셔닝 최적화, 셔플 파티션 최적화이며 각자 상황에 따라 실험해보며 최적화 방안을 생각해 볼 수 있을 것이다
